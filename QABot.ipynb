{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvSGDbExff_I"
   },
   "source": [
    "# QABot with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGOr_eS3wJJf"
   },
   "source": [
    "## Task description\n",
    "- Extractive Question Answering\n",
    "  - Input: Paragraph + Question\n",
    "  - Output: Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dKM4yCh4LI_"
   },
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WOTHHtWJoahe"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torch.optim import AdamW\n",
    "from transformers import BertForQuestionAnswering, BertTokenizerFast, get_cosine_schedule_with_warmup\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Fix random seed for reproducibility\n",
    "def same_seeds(seed):\n",
    "\t  torch.manual_seed(seed)\n",
    "\t  if torch.cuda.is_available():\n",
    "\t\t    torch.cuda.manual_seed(seed)\n",
    "\t\t    torch.cuda.manual_seed_all(seed)\n",
    "\t  np.random.seed(seed)\n",
    "\t  random.seed(seed)\n",
    "\t  torch.backends.cudnn.benchmark = False\n",
    "\t  torch.backends.cudnn.deterministic = True\n",
    "same_seeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7pBtSZP1SKQO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Change \"fp16_training\" to True to support automatic mixed precision training (fp16)\n",
    "fp16_training = True\n",
    "\n",
    "if fp16_training:\n",
    "    # !pip install accelerate==0.2.0\n",
    "    from accelerate import Accelerator\n",
    "    accelerator = Accelerator(mixed_precision='fp16')\n",
    "    device = accelerator.device\n",
    "    print(device)\n",
    "\n",
    "# Documentation for the toolkit:  https://huggingface.co/docs/accelerate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YgXHuVLp_6j"
   },
   "source": [
    "## Load Model and Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xyBCYGjAp3ym"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Td-GTmk5OW4"
   },
   "source": [
    "## Read Data\n",
    "\n",
    "- Training set: 87599 QA pairs\n",
    "  - max tokenized question length: 61\n",
    "  - max tokenized context length: 853\n",
    "- Dev set: 34726  QA pairs\n",
    "- Test set: try to generate via ChatGPT(to-do)\n",
    "\n",
    "\n",
    "dataset structure\n",
    "- title\n",
    "- paragraphs\n",
    "    - context\n",
    "    - qas\n",
    "      - answers\n",
    "        - answer_start\n",
    "        - test\n",
    "      - question\n",
    "      - id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    with open(file, 'rb') as reader:\n",
    "        data = json.load(reader)\n",
    "    contexts, questions, answers = [], [], []\n",
    "    for group in data['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                # question = qa['question']\n",
    "                # for answer in qa['answers']:\n",
    "                #     contexts.append(context)\n",
    "                #     questions.append(question)\n",
    "                #     answers.append(answer)\n",
    "                contexts.append(context)\n",
    "                questions.append(qa['question'])\n",
    "                answers.append(qa['answers'])\n",
    "    return contexts, questions, answers\n",
    "\n",
    "train_contexts, train_questions, train_answers = read_data(\"dataset/train-v1.1.json\")\n",
    "dev_contexts, dev_questions, dev_answers = read_data(\"dataset/dev-v1.1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10570"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(answer) for answer in train_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 8490, 5: 1147, 4: 759, 2: 136, 6: 35, 1: 3})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of number of answer per question in dev set\n",
    "from collections import Counter\n",
    "Counter(len(answer) for answer in dev_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}],\n",
       " [{'answer_start': 188, 'text': 'a copper statue of Christ'}],\n",
       " [{'answer_start': 279, 'text': 'the Main Building'}],\n",
       " [{'answer_start': 381, 'text': 'a Marian place of prayer and reflection'}],\n",
       " [{'answer_start': 92, 'text': 'a golden statue of the Virgin Mary'}],\n",
       " [{'answer_start': 248, 'text': 'September 1876'}],\n",
       " [{'answer_start': 441, 'text': 'twice'}],\n",
       " [{'answer_start': 598, 'text': 'The Observer'}],\n",
       " [{'answer_start': 126, 'text': 'three'}],\n",
       " [{'answer_start': 908, 'text': '1987'}]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answers[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mutiple answers to the same question in dev set, I guess it's for the accuracy of labeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which NFL team represented the AFC at Super Bowl 50?',\n",
       " 'Which NFL team represented the NFC at Super Bowl 50?',\n",
       " 'Where did Super Bowl 50 take place?',\n",
       " 'Which NFL team won Super Bowl 50?',\n",
       " 'What color was used to emphasize the 50th anniversary of the Super Bowl?']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'answer_start': 177, 'text': 'Denver Broncos'},\n",
       "  {'answer_start': 177, 'text': 'Denver Broncos'},\n",
       "  {'answer_start': 177, 'text': 'Denver Broncos'}],\n",
       " [{'answer_start': 249, 'text': 'Carolina Panthers'},\n",
       "  {'answer_start': 249, 'text': 'Carolina Panthers'},\n",
       "  {'answer_start': 249, 'text': 'Carolina Panthers'}],\n",
       " [{'answer_start': 403, 'text': 'Santa Clara, California'},\n",
       "  {'answer_start': 355, 'text': \"Levi's Stadium\"},\n",
       "  {'answer_start': 355,\n",
       "   'text': \"Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"}],\n",
       " [{'answer_start': 177, 'text': 'Denver Broncos'},\n",
       "  {'answer_start': 177, 'text': 'Denver Broncos'},\n",
       "  {'answer_start': 177, 'text': 'Denver Broncos'}],\n",
       " [{'answer_start': 488, 'text': 'gold'},\n",
       "  {'answer_start': 488, 'text': 'gold'},\n",
       "  {'answer_start': 521, 'text': 'gold'}]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What day was the game played on?',\n",
       " 'What is the AFC short for?',\n",
       " 'What was the theme of Super Bowl 50?']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_questions[6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'answer_start': 334, 'text': 'February 7, 2016'},\n",
       "  {'answer_start': 334, 'text': 'February 7'},\n",
       "  {'answer_start': 334, 'text': 'February 7, 2016'}],\n",
       " [{'answer_start': 133, 'text': 'American Football Conference'},\n",
       "  {'answer_start': 133, 'text': 'American Football Conference'},\n",
       "  {'answer_start': 133, 'text': 'American Football Conference'}],\n",
       " [{'answer_start': 487, 'text': '\"golden anniversary\"'},\n",
       "  {'answer_start': 521, 'text': 'gold-themed'},\n",
       "  {'answer_start': 521, 'text': 'gold'}]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_answers[6:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What day was the Super Bowl played on?',\n",
       " 'Who won Super Bowl 50?',\n",
       " 'What venue did Super Bowl 50 take place in?',\n",
       " 'What city did Super Bowl 50 take place in?',\n",
       " 'If Roman numerals were used, what would Super Bowl 50 have been called?']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_questions[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'answer_start': 334, 'text': 'February 7, 2016'},\n",
       "  {'answer_start': 334, 'text': 'February 7'},\n",
       "  {'answer_start': 334, 'text': 'February 7, 2016'}],\n",
       " [{'answer_start': 177, 'text': 'Denver Broncos'},\n",
       "  {'answer_start': 177, 'text': 'Denver Broncos'},\n",
       "  {'answer_start': 177, 'text': 'Denver Broncos'}],\n",
       " [{'answer_start': 355, 'text': \"Levi's Stadium\"},\n",
       "  {'answer_start': 355, 'text': \"Levi's Stadium\"},\n",
       "  {'answer_start': 355,\n",
       "   'text': \"Levi's Stadium in the San Francisco Bay Area at Santa Clara\"}],\n",
       " [{'answer_start': 403, 'text': 'Santa Clara'},\n",
       "  {'answer_start': 403, 'text': 'Santa Clara'},\n",
       "  {'answer_start': 403, 'text': 'Santa Clara'}],\n",
       " [{'answer_start': 693, 'text': 'Super Bowl L'},\n",
       "  {'answer_start': 704, 'text': 'L'},\n",
       "  {'answer_start': 693, 'text': 'Super Bowl L'}]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_answers[10:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm0rpTHq0e4N"
   },
   "source": [
    "## Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "rTZ6B70Hoxie"
   },
   "outputs": [],
   "source": [
    "# Tokenize questions and paragraphs separatelymixed_precision\n",
    "# 「add_special_tokens」 is set to False since special tokens will be added when tokenized questions and paragraphs are combined in datset __getitem__\n",
    "\n",
    "train_questions_tokenized = tokenizer([train_question for train_question in train_questions], add_special_tokens=False)\n",
    "dev_questions_tokenized = tokenizer([dev_question for dev_question in dev_questions], add_special_tokens=False)\n",
    "\n",
    "train_contexts_tokenized = tokenizer(train_contexts, add_special_tokens=False)\n",
    "dev_contexts_tokenized = tokenizer(dev_contexts, add_special_tokens=False)\n",
    "\n",
    "\n",
    "# tokenized sequences will be futher processed in datset __getitem__ before passing to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_tokens_per_context = [len(tokens) for tokens in train_contexts_tokenized['input_ids']]\n",
    "\n",
    "# Plotting the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(num_tokens_per_context, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Distribution of Number of Tokens per Context')\n",
    "plt.xlabel('Number of Tokens')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_questions_tokenized['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87599"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max tokenized question length\n",
    "max(len(train_questions_tokenized['input_ids'][i]) for i in range(len(train_questions_tokenized['input_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "853"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max tokenized question length\n",
    "max(len(train_contexts_tokenized['input_ids'][i]) for i in range(len(train_contexts_tokenized['input_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts_tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6549,\n",
       " 2135,\n",
       " 1010,\n",
       " 1996,\n",
       " 2082,\n",
       " 2038,\n",
       " 1037,\n",
       " 3234,\n",
       " 2839,\n",
       " 1012,\n",
       " 10234,\n",
       " 1996,\n",
       " 2364,\n",
       " 2311,\n",
       " 1005,\n",
       " 1055,\n",
       " 2751,\n",
       " 8514,\n",
       " 2003,\n",
       " 1037,\n",
       " 3585,\n",
       " 6231,\n",
       " 1997,\n",
       " 1996,\n",
       " 6261,\n",
       " 2984,\n",
       " 1012,\n",
       " 3202,\n",
       " 1999,\n",
       " 2392,\n",
       " 1997,\n",
       " 1996,\n",
       " 2364,\n",
       " 2311,\n",
       " 1998,\n",
       " 5307,\n",
       " 2009,\n",
       " 1010,\n",
       " 2003,\n",
       " 1037,\n",
       " 6967,\n",
       " 6231,\n",
       " 1997,\n",
       " 4828,\n",
       " 2007,\n",
       " 2608,\n",
       " 2039,\n",
       " 14995,\n",
       " 6924,\n",
       " 2007,\n",
       " 1996,\n",
       " 5722,\n",
       " 1000,\n",
       " 2310,\n",
       " 3490,\n",
       " 2618,\n",
       " 4748,\n",
       " 2033,\n",
       " 18168,\n",
       " 5267,\n",
       " 1000,\n",
       " 1012,\n",
       " 2279,\n",
       " 2000,\n",
       " 1996,\n",
       " 2364,\n",
       " 2311,\n",
       " 2003,\n",
       " 1996,\n",
       " 13546,\n",
       " 1997,\n",
       " 1996,\n",
       " 6730,\n",
       " 2540,\n",
       " 1012,\n",
       " 3202,\n",
       " 2369,\n",
       " 1996,\n",
       " 13546,\n",
       " 2003,\n",
       " 1996,\n",
       " 24665,\n",
       " 23052,\n",
       " 1010,\n",
       " 1037,\n",
       " 14042,\n",
       " 2173,\n",
       " 1997,\n",
       " 7083,\n",
       " 1998,\n",
       " 9185,\n",
       " 1012,\n",
       " 2009,\n",
       " 2003,\n",
       " 1037,\n",
       " 15059,\n",
       " 1997,\n",
       " 1996,\n",
       " 24665,\n",
       " 23052,\n",
       " 2012,\n",
       " 10223,\n",
       " 26371,\n",
       " 1010,\n",
       " 2605,\n",
       " 2073,\n",
       " 1996,\n",
       " 6261,\n",
       " 2984,\n",
       " 22353,\n",
       " 2135,\n",
       " 2596,\n",
       " 2000,\n",
       " 3002,\n",
       " 16595,\n",
       " 9648,\n",
       " 4674,\n",
       " 2061,\n",
       " 12083,\n",
       " 9711,\n",
       " 2271,\n",
       " 1999,\n",
       " 8517,\n",
       " 1012,\n",
       " 2012,\n",
       " 1996,\n",
       " 2203,\n",
       " 1997,\n",
       " 1996,\n",
       " 2364,\n",
       " 3298,\n",
       " 1006,\n",
       " 1998,\n",
       " 1999,\n",
       " 1037,\n",
       " 3622,\n",
       " 2240,\n",
       " 2008,\n",
       " 8539,\n",
       " 2083,\n",
       " 1017,\n",
       " 11342,\n",
       " 1998,\n",
       " 1996,\n",
       " 2751,\n",
       " 8514,\n",
       " 1007,\n",
       " 1010,\n",
       " 2003,\n",
       " 1037,\n",
       " 3722,\n",
       " 1010,\n",
       " 2715,\n",
       " 2962,\n",
       " 6231,\n",
       " 1997,\n",
       " 2984,\n",
       " 1012]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_contexts_tokenized[0].ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['to',\n",
       " 'whom',\n",
       " 'did',\n",
       " 'the',\n",
       " 'virgin',\n",
       " 'mary',\n",
       " 'allegedly',\n",
       " 'appear',\n",
       " 'in',\n",
       " '1858',\n",
       " 'in',\n",
       " 'lou',\n",
       " '##rdes',\n",
       " 'france',\n",
       " '?']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_tokenized[0].tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws8c8_4d5UCI"
   },
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "Xjooag-Swnuh"
   },
   "outputs": [],
   "source": [
    "class QA_Dataset(Dataset):\n",
    "    doc_stride = 50\n",
    "    \n",
    "    def __init__(self, split, answers, questions, tokenized_questions, tokenized_contexts, random_training_window=True):\n",
    "        self.split = split\n",
    "        self.answers = answers\n",
    "        self.questions = questions\n",
    "        self.tokenized_questions = tokenized_questions\n",
    "        self.tokenized_contexts = tokenized_contexts\n",
    "        self.random_training_window = random_training_window\n",
    "        self.max_question_len = 40\n",
    "        self.max_context_len = 150 # maybe better to change it to 100, based on the distribution of num of tokens in the contexts\n",
    "\n",
    "        # Input sequence length = [CLS] + question + [SEP] + context + [SEP]\n",
    "        self.max_seq_len = 1 + self.max_question_len + 1 + self.max_context_len + 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        answer = self.answers[idx][0] # self.answers[idx] is a list, for training set, the length of the list is 1.\n",
    "        question = self.questions[idx]\n",
    "        tokenized_question = self.tokenized_questions[idx]\n",
    "        tokenized_context = self.tokenized_contexts[idx]\n",
    "\n",
    "\n",
    "        if self.split == \"train\":\n",
    "            # Convert answer's start/end positions in context_text to start/end positions in tokenized_context\n",
    "            answer_start = answer['answer_start']\n",
    "            answer_len = len(answer['text'])\n",
    "            answer_end = answer_start + answer_len - 1\n",
    "            \n",
    "            answer_start_token = tokenized_context.char_to_token(answer_start)\n",
    "            answer_end_token = tokenized_context.char_to_token(answer_end)\n",
    "\n",
    "            # A single window is obtained by slicing the portion of context containing the answer\n",
    "            if self.random_training_window:\n",
    "                context_start_min = max(0, answer_end_token - self.max_context_len + 1)\n",
    "                context_start_max = max(0, min(answer_start_token, len(tokenized_context) - self.max_context_len))\n",
    "                context_start = random.randint(context_start_min, context_start_max + 1)    \n",
    "            else:\n",
    "                mid = (answer_start_token + answer_end_token) // 2\n",
    "                context_start = max(0, min(mid - self.max_context_len // 2, len(tokenized_context) - self.max_context_len))\n",
    "                \n",
    "            context_end = context_start + self.max_context_len\n",
    "\n",
    "            # Slice question/context and add special tokens (101: CLS, 102: SEP)\n",
    "            input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n",
    "            input_ids_context = tokenized_context.ids[context_start : context_end] + [102]\n",
    "\n",
    "            # Convert answer's start/end positions in tokenized_context to start/end positions in the window\n",
    "            answer_start_token += len(input_ids_question) - context_start\n",
    "            answer_end_token += len(input_ids_question) - context_start\n",
    "\n",
    "            # Pad sequence and obtain inputs to model\n",
    "            input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_context)\n",
    "            return torch.tensor(input_ids), torch.tensor(token_type_ids), torch.tensor(attention_mask), answer_start_token, answer_end_token\n",
    "\n",
    "        # Validation/Testing\n",
    "        else:\n",
    "            input_ids_list, token_type_ids_list, attention_mask_list = [], [], []\n",
    "\n",
    "            # context is split into several windows, each with start positions separated by step \"doc_stride\"\n",
    "            for i in range(0, len(tokenized_context), self.doc_stride):\n",
    "\n",
    "                # Slice question/context and add special tokens (101: CLS, 102: SEP)\n",
    "                input_ids_question = [101] + tokenized_question.ids[:self.max_question_len] + [102]\n",
    "                input_ids_context = tokenized_context.ids[i : i + self.max_context_len] + [102]\n",
    "\n",
    "                # Pad sequence and obtain inputs to model\n",
    "                input_ids, token_type_ids, attention_mask = self.padding(input_ids_question, input_ids_context)\n",
    "\n",
    "                input_ids_list.append(input_ids)\n",
    "                token_type_ids_list.append(token_type_ids)\n",
    "                attention_mask_list.append(attention_mask)\n",
    "\n",
    "            return torch.tensor(input_ids_list), torch.tensor(token_type_ids_list), torch.tensor(attention_mask_list)\n",
    "\n",
    "    def padding(self, input_ids_question, input_ids_context):\n",
    "        # Pad zeros if sequence length is shorter than max_seq_len\n",
    "        padding_len = self.max_seq_len - len(input_ids_question) - len(input_ids_context)\n",
    "        # Indices of input sequence tokens in the vocabulary\n",
    "        input_ids = input_ids_question + input_ids_context + [0] * padding_len\n",
    "        # Segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]\n",
    "        token_type_ids = [0] * len(input_ids_question) + [1] * len(input_ids_context) + [0] * padding_len\n",
    "        # Mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]\n",
    "        attention_mask = [1] * (len(input_ids_question) + len(input_ids_context)) + [0] * padding_len\n",
    "\n",
    "        return input_ids, token_type_ids, attention_mask\n",
    "\n",
    "train_set = QA_Dataset(\"train\", train_answers, train_questions, train_questions_tokenized, train_contexts_tokenized, random_training_window=True)\n",
    "dev_set = QA_Dataset(\"dev\", dev_answers, dev_questions, dev_questions_tokenized, dev_contexts_tokenized)\n",
    "# test_set = QA_Dataset(\"test\", test_questions, test_questions_tokenized, test_contexts_tokenized)\n",
    "\n",
    "train_batch_size = 16\n",
    "\n",
    "# Note: Do NOT change batch size of dev_loader / test_loader !\n",
    "# Although batch size=1, it is actually a batch consisting of several windows from the same QA pair\n",
    "train_loader = DataLoader(train_set, batch_size=train_batch_size, shuffle=True, pin_memory=True)\n",
    "dev_loader = DataLoader(dev_set, batch_size=1, shuffle=False, pin_memory=True)\n",
    "# test_loader = DataLoader(test_set, batch_size=1, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 101, 2040, 2180,  ...,    0,    0,    0],\n",
       "         [ 101, 1999, 2054,  ...,    0,    0,    0],\n",
       "         [ 101, 2054, 2106,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 2054, 2003,  ...,    0,    0,    0],\n",
       "         [ 101, 2054, 2003,  ...,    0,    0,    0],\n",
       "         [ 101, 2043, 2003,  ...,    0,    0,    0]]),\n",
       " tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([104,  31, 160, 132,  52,  23,  66,  82,  71,  24,  13,  43,  45,  60,\n",
       "         142,  91]),\n",
       " tensor([112,  32, 164, 135,  54,  23,  83,  83,  72,  25,  31,  45,  47,  64,\n",
       "         146,  91])]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(data_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_H1kqhR8CdM"
   },
   "source": [
    "## Function for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "SqeA3PLPxOHu"
   },
   "outputs": [],
   "source": [
    "def evaluate(data, output, split=None, question_id=None):\n",
    "\n",
    "    answer = ''\n",
    "    answer_start_idx = -1\n",
    "    answer_end_idx = -1\n",
    "    max_prob = float('-inf')\n",
    "    num_of_windows = data[0].shape[1]\n",
    "\n",
    "    for k in range(num_of_windows):\n",
    "        # Obtain answer by choosing the most probable start position / end position\n",
    "        start_prob, start_index = torch.max(output.start_logits[k], dim=0)\n",
    "        end_prob, end_index = torch.max(output.end_logits[k], dim=0)\n",
    "        \n",
    "        token_type_id = data[1][0][k].detach().cpu().numpy()\n",
    "        # [CLS] + [question] + [SEP] + [paragraph] + [SEP]\n",
    "        paragraph_start = token_type_id.argmax()\n",
    "        paragraph_end = len(token_type_id) - 1 - token_type_id[::-1].argmax()\n",
    "        \n",
    "        if start_index > end_index or start_index < paragraph_start or end_index > paragraph_end :\n",
    "            continue\n",
    "            \n",
    "\n",
    "        # Probability of answer is calculated as sum of start_prob and end_prob\n",
    "        prob = start_prob + end_prob\n",
    "\n",
    "        # Replace answer if calculated probability is larger than previous windows\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            # Convert tokens to chars (e.g. [1920, 7032] --> \"大 金\")\n",
    "            answer = tokenizer.decode(data[0][0][k][start_index : end_index + 1])\n",
    "            answer_start_idx = start_index\n",
    "            answer_end_idx = end_index\n",
    "            \n",
    "            origin_start = start_index - paragraph_start + k * QA_Dataset.doc_stride \n",
    "            origin_end = end_index - paragraph_start + k * QA_Dataset.doc_stride \n",
    "            \n",
    "    answer = answer.replace(' ','')\n",
    "\n",
    "    if '[UNK]' in answer:\n",
    "        # find the original subtext based on the start and end index, replace the answer with the subtext\n",
    "        if split == 'dev':\n",
    "            print(dev_questions[question_id][\"answer_text\"])\n",
    "            paragraph_tokenized = dev_paragraphs_tokenized[dev_questions[question_id][\"paragraph_id\"]]\n",
    "            raw_start = paragraph_tokenized.token_to_chars(origin_start)[0]\n",
    "            raw_end = paragraph_tokenized.token_to_chars(origin_end)[1]\n",
    "            answer = dev_paragraphs[dev_questions[question_id][\"paragraph_id\"]][raw_start:raw_end]\n",
    "            print(answer)\n",
    "        if split == 'test':\n",
    "            paragraph_tokenized = test_paragraphs_tokenized[test_questions[question_id][\"paragraph_id\"]]\n",
    "            raw_start = paragraph_tokenized.token_to_chars(origin_start)[0]\n",
    "            raw_end = paragraph_tokenized.token_to_chars(origin_end)[1]\n",
    "            answer = test_paragraphs[test_questions[question_id][\"paragraph_id\"]][raw_start:raw_end]\n",
    "    \n",
    "\n",
    "    return answer, answer_start_idx, answer_end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzHQit6eMnKG"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "3Q-B6ka7xoCM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training ...\n",
      "Evaluating Dev Set ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a619ee33ec478aa56d9c7d2cb1c10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3524 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "番人的反抗\n",
      "大肚平埔族拍布拉族大肚王與瑯嶠番人的反抗\n",
      "約旦的Jawa大壩\n",
      "Jawa大壩\n",
      "《阿闥婆吠陀》\n",
      "《阿闥婆吠陀》\n",
      "姚萇\n",
      "姚萇\n",
      "淝水之戰\n",
      "淝水之戰\n",
      "金堉\n",
      "金堉\n",
      "P-61\n",
      "P-61戰鬥機\n",
      "奕訢\n",
      "奕訢\n",
      "撣族\n",
      "撣族\n",
      "3000垓\n",
      "3000垓顆\n",
      "共產黨情報局\n",
      "史達林設置用於控制東歐共產黨的機關—共產黨情報局\n",
      "祕色瓷\n",
      "——祕色瓷\n",
      "128\n",
      "512 KB\n",
      "ANP\n",
      "ANP\n",
      "T.C.B.S\n",
      "T.C.B.S\n",
      "收買人心\n",
      "Matamoros自治市\n",
      "紅河戰役\n",
      "Palmito Ranch戰役\n",
      "LOEN娛樂\n",
      "韓國第三大財閥SK集團\n",
      "回鶻汗國\n",
      "回鶻汗國\n",
      "白堊紀\n",
      "白堊紀\n",
      "羅塞塔號的菲萊登陸器\n",
      "菲萊登陸器於2014年11月12日在彗星上登陸，就是67P/楚留莫夫－格拉希門克彗星\n",
      "F-16戰鬥機\n",
      "F-16戰鬥機\n",
      "白堊紀中期\n",
      "白堊紀中期\n",
      "回鶻部落\n",
      "回鶻部落\n",
      "白堊紀\n",
      "白堊紀\n",
      "小綠人\n",
      "KTV\n",
      "HK G3自動步槍系列\n",
      "HK G3自動步槍\n",
      "Mosaic網頁瀏覽器\n",
      "Mosaic網頁瀏覽器\n",
      "製糖會社\n",
      "李俊俋\n",
      "TR-850型\n",
      "TR-850\n",
      "普賢菩薩\n",
      "—樂山大佛\n",
      "「Harvey獎」\n",
      "Harvey獎\n",
      "蔡鍔\n",
      "蔡鍔\n",
      "A型機動腳踏車\n",
      "本田A型機動腳踏車\n",
      "一種導入人工智慧化的新世代BRT系統\n",
      "導入人工智慧化的新世代BRT系統\n",
      "久彌宮妃俔子\n",
      "久彌宮妃俔子\n",
      "《BBC早餐》\n",
      "《BBC早餐》\n",
      "《阿闥婆吠陀》\n",
      "《阿闥婆吠陀》\n",
      "全球資訊網專案簡介\n",
      "Mosaic網頁瀏覽器\n",
      "使用過時的二衝程發動機\n",
      "其中含有烴，廢氣具有明顯氣味和顏色\n",
      "盤瓠蠻\n",
      "盤瓠蠻\n",
      "李勣\n",
      "李勣\n",
      "玄奘法師\n",
      "支婁迦讖\n",
      "Validation | Epoch 1 | acc = 0.000\n",
      "Saving Model ...\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "validation = True\n",
    "logging_step = 100\n",
    "learning_rate = 1e-4\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_step = len(train_loader) * num_epoch\n",
    "\n",
    "linear_learning_rate_decay = False\n",
    "schedule_with_warm_up = True\n",
    "\n",
    "if linear_learning_rate_decay and schedule_with_warm_up:\n",
    "    linear_learning_rate_decay = False\n",
    "\n",
    "if schedule_with_warm_up:\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=total_step//10, num_training_steps=total_step)\n",
    "\n",
    "if fp16_training:\n",
    "    if schedule_with_warm_up:\n",
    "        model, optimizer, train_loader, lr_scheduler = accelerator.prepare(model,\n",
    "                                                                           optimizer, \n",
    "                                                                           train_loader,\n",
    "                                                                           scheduler)\n",
    "    else:\n",
    "        model, optimizer, train_loader = accelerator.prepare(model, \n",
    "                                                             optimizer, \n",
    "                                                             train_loader)\n",
    "\n",
    "model.train()\n",
    "\n",
    "print(\"Start Training ...\")\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    step = 1\n",
    "    train_loss = train_acc = 0\n",
    "\n",
    "    for data in tqdm(train_loader):\n",
    "        # Load all data into GPU\n",
    "        data = [i.to(device) for i in data]\n",
    "\n",
    "        # Model inputs: input_ids, token_type_ids, attention_mask, start_positions, end_positions (Note: only \"input_ids\" is mandatory)\n",
    "        # Model outputs: start_logits, end_logits, loss (return when start_positions/end_positions are provided)\n",
    "        output = model(input_ids=data[0], token_type_ids=data[1], attention_mask=data[2], start_positions=data[3], end_positions=data[4])\n",
    "\n",
    "        # Choose the most probable start position / end position\n",
    "        start_index = torch.argmax(output.start_logits, dim=1)\n",
    "        end_index = torch.argmax(output.end_logits, dim=1)\n",
    "\n",
    "        # Prediction is correct only if both start_index and end_index are correct\n",
    "        train_acc += ((start_index == data[3]) & (end_index == data[4])).float().mean()\n",
    "        train_loss += output.loss\n",
    "\n",
    "        if fp16_training:\n",
    "            accelerator.backward(output.loss)\n",
    "        else:\n",
    "            output.loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        if linear_learning_rate_decay:\n",
    "            optimizer.param_groups[0]['lr'] -= learning_rate / total_step \n",
    "        if schedule_with_warm_up:\n",
    "            scheduler.step()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        step += 1\n",
    "\n",
    "\n",
    "        # Print training loss and accuracy over past logging step\n",
    "        if step % logging_step == 0:\n",
    "            print(f\"Epoch {epoch + 1} | Step {step} | loss = {train_loss.item() / logging_step:.3f}, acc = {train_acc / logging_step:.3f}\")\n",
    "            train_loss = train_acc = 0\n",
    "\n",
    "    if validation:\n",
    "        print(\"Evaluating Dev Set ...\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            dev_acc = 0\n",
    "            for i, data in enumerate(tqdm(dev_loader)):\n",
    "                output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
    "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
    "                # prediction is correct only if answer text exactly matches\n",
    "                dev_acc += evaluate(data, \n",
    "                                    output, \n",
    "                                    split='dev', \n",
    "                                    question_id=i\n",
    "                                   ) == dev_questions[i][\"answer_text\"]\n",
    "            print(f\"Validation | Epoch {epoch + 1} | acc = {dev_acc / len(dev_loader):.3f}\")\n",
    "        model.train()\n",
    "\n",
    "# Save a model and its configuration file to the directory 「saved_model」\n",
    "# i.e. there are two files under the direcory 「saved_model」: 「pytorch_model.bin」 and 「config.json」\n",
    "# Saved model can be re-loaded using 「model = BertForQuestionAnswering.from_pretrained(\"saved_model\")」\n",
    "print(\"Saving Model ...\")\n",
    "model_save_dir = \"saved_model\"\n",
    "model.save_pretrained(model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMmdLOKBMsdE"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "U5scNKC9xz0C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Test Set ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baaf0180d3274f1797121b9e818768c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3493 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed! Result is in results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Test Set ...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(test_loader)):\n",
    "        output = model(input_ids=data[0].squeeze(dim=0).to(device), token_type_ids=data[1].squeeze(dim=0).to(device),\n",
    "                       attention_mask=data[2].squeeze(dim=0).to(device))\n",
    "        result, start_idx, end_idx = evaluate(data, \n",
    "                                              output, \n",
    "                                              split='test', \n",
    "                                              question_id=i)\n",
    "        # print(f\"question {len(results)}, start:{start_idx}, end:{end_idx}\" )\n",
    "        results.append(result)\n",
    "\n",
    "result_file = \"results.csv\"\n",
    "with open(result_file, 'w') as f:\n",
    "\t  f.write(\"ID,Answer\\n\")\n",
    "\t  for i, test_question in enumerate(test_questions):\n",
    "        # Replace commas in answers with empty strings (since csv is separated by comma)\n",
    "        # Answers in kaggle are processed in the same way\n",
    "\t\t    f.write(f\"{test_question['id']},{results[i].replace(',','')}\\n\")\n",
    "\n",
    "print(f\"Completed! Result is in {result_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "hw7_bert",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
